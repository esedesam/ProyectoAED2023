---
title: Proyecto Análisis Exploratorio de Datos 2023
author:
  - name: Javier Hinarejos Albero
    affil: 1, \dagger
  - name: Samuel Ortega Mediavilla
    affil: 1, \dagger, *
affiliation:
  - num: 1
    address: |
      Universitat de València - 
      Escuela Técnica Superior de Ingeniería
      Avenida de la Universitat s/n 46100 Burjassot. Valencia. España
# author citation list in chicago format
authorcitation: |
  Hinarejos, J.; Ortega, S.
# firstnote to eighthnote
firstnote: |
  Estos autores contribuyeron de manera equitativa a este trabajo.
correspondence: |
  saorme@alumni.uv.es.
# document options
journal: notspecified
type: article
status: submit
# front matter
simplesummary: |
  El dataset de variaciones residenciales del INE (2021) contiene los datos de los
  cambios de residencia con origen y/o destino en España durante el año 2021.
abstract: |
  Este trabajo presenta un análisis exploratorio de datos basado en un conjunto de datos de variaciones residenciales en España durante el año 2021. Se examinan las fluctuaciones en la residencia de personas, destacando tanto las altas como las bajas ocurridas a lo largo del año. A través de técnicas estadísticas y visualizaciones, se identifican patrones y tendencias en los movimientos de población, proporcionando una comprensión detallada de las dinámicas residenciales en el contexto español durante este periodo. Este análisis contribuye a una mejor comprensión de los cambios demográficos y puede ser fundamental para la toma de decisiones en planificación urbana y políticas de vivienda.
# back matter
keywords: |
  AED, ciencia de datos, ine, preprocesamiento, visualización, correlación
acknowledgement: |
  Hasta la fecha de publicación, no se ha recibido ningún tipo de financiamiento
  para este proyecto.
authorcontributions: |
  S.O. y J.H. hicieron la búsqueda y selección del datasetM S.O. realizó el
  preprocesamiento de los datos; J.H. realizó un análisis estadístico profundo de
  los datos procesados; S.O. y J.H. realizaron las representaciones gráficas;
  S.O. y J.H. redactaron el trabajo.
funding: |
  Este proyecto no ha recibido financiación externa.
institutionalreview: |
  El estudio se ha realizado de acuerdo a la licencia de libre disposición de los
  datos anonimizados del INE.
informedconsent: |
  No aplicable.
dataavailability: |
  Los resultados de este proyecto se pueden encontrar en el repositorio de GitHub
  creado a fin de contenerlo: https://github.com/esedesam/ProyectoAED2023.git.
conflictsofinterest: |
  Los autores declaran la ausencia de conflictos de intereses.
sampleavailability: |
  Los datos están disponibles en la página web del INE.
supplementary: |
  No hay información de apoyo disponible.
abbreviations:
  - short: INE
    long: Instituto Nacional de Estadística
  - short: AED
    long: Análisis Exploratorio de Datos
bibliography: mybibfile.bib
# appendix: appendix.tex
endnotes: false
output: 
  rticles::mdpi_article:
    extra_dependencies: longtable
---

```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# Configuración general de chunks
if (!require(knitr)) {
  install.packages("knitr")
  library(knitr)
}
base::options(width = 50, digits = 3)
knitr::opts_chunk$set(echo = F, include = T, message = T, error = F, warning = F, comment = NA, dpi = 100, tidy = T, cache.path = '.cache/', fig.path = './figure/', fig.width = 5, fig.height = 3, fig.align = "center")
useJPGs <- TRUE
```

```{r packages, message = F}
# Carga de paquetes necesarios con pacman
if (!require(pacman)) {
  install.packages("pacman")
  library(pacman)
}
pacman::p_load(kableExtra, readxl, stringr, tidyr, dplyr, ggmap, leaflet, leaflet.extras, leaflet.extras2, sf, colorspace, car, fitdistrplus, ggmosaic, JPEG, imager)
```

# Datos seleccionados

Hemos escogido los datos de variaciones residenciales en 2021 del INE. Estos datos están disponibles en el siguiente enlace: [https://go.uv.es/saorme/ine-var-res-2021](https://go.uv.es/saorme/ine-var-res-2021).

Adicionalmente, hemos empleado la relación de municipios de 2021, disponible en: [https://go.uv.es/saorme/ine-muni-2021](https://go.uv.es/saorme/ine-muni-2021).

Se trata de una base de microdatos del INE, procedente de las encuestas realizadas a lo largo de ese mismo año.

## Preguntas planteadas

 - ¿Se concentran las variaciones residenciales durante alguna época concreta del año?
 - ¿Hay alguna dependencia de la cantidad de variaciones residenciales con la edad? Si es así, ¿depende también de la edad?
 - ¿Cómo es la tasa de migración de España con el extranjero?
 - ¿Hay una relación significativa entre el tamaño de los municipios y el número de variaciones que se producen en ellos? ¿Es el éxodo rural un problema actual?

# Previsualización de los datos

En el fichero principal de datos `md_EVR_2021.txt`, observamos que cada registro contiene una cadena de caracteres de longitud fija. Su interpretación viene detallada en el fichero adicional de metadatos `dr_EVR_2021.xlsx`.

```{r preview}
raw_data_preview <- readLines('./data/md_EVR_2021.txt', n = 3)
kable(raw_data_preview)
```

# Lectura de funciones

Las funciones definidas para el procesado de este dataset están disponibles en el fichero `ProyectoAED2023_library.R`.

```{r def-functions}
prev_objects <- ls()
source("ProyectoAED2023_library.R")
new_objects <- ls()
loaded_functions <- new_objects[!(new_objects %in% prev_objects)]
cat("Funciones cargadas: ", paste0(loaded_functions, collapse = ", "))
```

# Lectura de los ficheros

En primer lugar, leemos la información de todos los ficheros necesarios: el fichero principal, el excel de metadatos y el excel que contiene el diccionario de municipios.

Para ello, hacemos uso de las funciones `readLines()` y `readxl::read_excel()`. Las hojas adicionales del excel de metadatos, que contienen los diccionarios de las distintas variables, se almacenan en una lista.

```{r load-files}
data_file <- "./data/md_EVR_2021.txt"
excel_dict_file <- "./data/dr_EVR_2021.xlsx"
main_sheet <- "Diseño"
municipios_file <- "./data/diccionario21.xlsx"

raw_data <- readLines(data_file, encoding = "UTF-8")

vars_table <- read_excel(excel_dict_file, sheet = main_sheet,
                         range = "A2:J19", col_names = TRUE)

sheet_list <- load_excel_dicts(excel_dict_file)
municipios_data <- read_excel(municipios_file, skip = 1,
                                  col_names = TRUE)
```

# Preprocesado

## Limpieza de longitud incorrecta

Como primera comprobación, nos aseguramos de que todas las entradas de los datos crudos tienen la longitud adecuada. Este valor está definido en la tabla de metadatos.

```{r check-length}
entry_length <- vars_table$Longitud[vars_table$Variable == "TOTAL"]

filtered_raw_data <- raw_data[nchar(raw_data) == entry_length]

# No necesitamos la última entrada para nada más
vars_table <- vars_table[vars_table$Variable != "TOTAL", ]
```

## Creación del dataframe

Una vez nos hemos asegurado de que todas las entradas tienen la longitud correcta, dividimos cada una de ellas en distintas variables de un `data.frame` a partir de las posiciones y longitudes definidas en los metadatos.

```{r split-data}
raw_data_df <- split_raw_data(filtered_raw_data, vars_table)
```

## Obtención de los diccionarios

A continuación, extraemos de los ficheros adicionales la información necesaria para interpretar los códigos de los datos crudos. Generamos dos variables:

 - `dict_list`: es una lista, en la cual cada elemento corresponde a un diccionario. A su vez, estos elementos son listas, que contienen información útil: la hoja donde se encuentra el diccionario, las variables a las que debe ser aplicado, y un valor lógico que indica si debe ser combinado con el diccionario adicional de municipios.
 
 - `dict_info`: es un `data.frame` en el que almacenamos los códigos y descripciones de todos los diccionarios a aplicar. Dado que los códigos no son únicos entre los distintos diccionarios, también añadimos una columna que indica el nombre del diccionario.

```{r get-dicts}
dict_list <- create_dict_list(vars_table)
dict_info <- get_dict_from_sheets(dict_list, sheet_list, municipios_data)
```

## Interpretación de los códigos de las variables

Una vez obtenidos los diccionarios, los aplicamos a los datos crudos divididos. Para ello, seleccionamos cada uno de los diccionarios descritos en `dict_list` y los aplicamos a todas las variables que ahí se indican, variable a variable.

El intercambio de código a descripción se realiza definiendo cada variable como un `factor` cuyos niveles son los códigos y las etiquetas, las descripciones. Este método ha resultado ser más rápido que la búsqueda de coincidencias variable-código y sustitución con la descripción empleando la función `match()`.

```{r apply-dicts}
data_df <- apply_dict_to_data(raw_data_df, dict_info, dict_list)
```

Adicionalmente, verificamos que la interpretación se ha realizado correctamente. Para ello, buscamos los valores no disponibles en el nuevo `data.frame` que no eran `NAs` en el original, y comprobamos si proceden de códigos mal interpretados o, por el contrario, corresponden a entradas en blanco.

```{r check-na}
na_summary <- check_na_procedence(raw_data_df, data_df)

kable(na_summary)
```

El último paso del preprocesado del dataset es la conversión de las variables para al formato adecuado. Está indicado en los metadatos, donde figuran dos tipos:

 - N: numérico -> `numeric`
 - A: alfanumérico -> `factor`

```{r convert-num}
data_df <- convert_numeric_vars(data_df, vars_table)
```

# Análisis de las variables

## Análisis univariante

En primer lugar, realizamos un summary para obtener la información esencial de cada variable.

```{r summ-data}
summary(data_df)
```

Seguidamente, observamos el tipo de cada variable para confirmar que estén en el formato adecuado.

```{r str-data}
str(data_df)
```

Tras observar las diferentes variables del conjunto de datos, decidimos eliminar aquellas variables que no aportan información valiosa en nuestro conjunto de datos.

```{r elim-vars1}
elim <- c('MESNAC', 'ANOVAR')

data_df <- data_df[, !(names(data_df) %in% elim)]
```

Decidimos eliminar las variables:

 - **MESNAC**: Consideramos que no aporta valor el mes de nacimiento de una persona.

 - **ANOVAR**: Todos los datos provienen del año 2021.

Otra variable que es posible que no sea de mucho interés es **MESVAR**, pero de momento decidimos no eliminarla para estudiar si existe alguna época del año en la cual las personas decidan cambiar de residencia con mayor frecuencia.

Por otra parte, creamos nuevas variables que contienen las comunidades autónomas, para poder analizar también las variaciones residenciales entre ellas. Para ello, aprovechamos el diccionario de municipios, ya que en él también aparecen codificadas las comunidades autónomas. Dado que las variables de municipios presentan muchos NAs, intentamos imputar las comunidades autónomas faltantes buscando coincidencias de la provincia.

En las nuevas variables de comunidades autónomas, las localizaciones en el extranjero están codificadas como "Extranjero".

```{r add-comu}
data_df <- add_comu_variables(data_df, municipios_data, raw_data_df)
```

```{r numer}
# Análisis variables numericas
numer<- data_df %>%
  select_if(is.numeric)

plot_file <- "./figure/boxplot_edad.jpg"
if (!useJPGs | !file.exists(plot_file)) {
  jpeg(plot_file, width = 500, height = 350)
  boxplot(numer$EDAD)
  dev.off()
}
img <- load.image(plot_file)
par(mar = c(0, 0, 0, 0))
plot(img, axes = FALSE)


plot_file <- "./figure/descdist_edad.jpg"
if (!useJPGs | !file.exists(plot_file)) {
  jpeg(plot_file, width = 500, height = 350)
  descdist(numer$EDAD)
  dev.off()
}
img <- load.image(plot_file)
par(mar = c(0, 0, 0, 0))
plot(img, axes = FALSE)

plot_file <- "./figure/descdist_mesvar.jpg"
if (!useJPGs | !file.exists(plot_file)) {
  jpeg(plot_file, width = 500, height = 350)
  descdist(numer$MESVAR)
  dev.off()
}
img <- load.image(plot_file)
par(mar = c(0, 0, 0, 0))
plot(img, axes = FALSE)
```

Mediante los gráficos de Cullen y Frey observamos que la variable MESVAR la podemos aproximar mediante una función uniforme. Por tanto, podemos eliminarla también ya que no aporta valor a nuestro conjunto de datos. Si tuviésemos datos de más años podríamos calcular la serie temporal y observar si hay alguna relación entre mudarse y el mes de cambio de residencia. Por otra parte, la variable Edad nos indica que se puede ajustar bajo una distribución gamma, lo cual tiene sentido, ya que la mediana es 35.7 y sin embargo, alcanza valores de hasta 111 años. Esto es debido a que la mayor parte de la gente se muda alrededor de la treintena y una vez ya han conseguido un trabajo y una familia estable, la decisión de cambiar de residencia es cada vez más complicada.

```{r elim-vars2}
elim <- c('MESVAR')

data_df <- data_df[, !(names(data_df) %in% elim)]
```

A pesar de ser una distribución gamma, mediante la función `qqPlot()` vemos si se puede aproximar también mediante una distribución normal y observamos que no sería una representación idónea.

```{r qqplot}
plot_file <- "./figure/qqplot_edad.jpg"
if (!useJPGs | !file.exists(plot_file)) {
  jpeg(plot_file, width = 500, height = 350)
  qqPlot(
    data_df$EDAD[!is.na(data_df$EDAD)],
    distribution = "norm",
    id = FALSE,
    ylab = "Cuantiles de edad")
  dev.off()
}
img <- load.image(plot_file)
par(mar = c(0, 0, 0, 0))
plot(img, axes = FALSE)
```

## Análisis univariante (Variables Categóricas)

Tras analizar las edades y el mes de variación, planteamos otra cuestión de vital importancia como es el hecho de estudiar el éxodo rural. Para ello, decidimos estudiar el movimiento entre provincias. 

```{r univ-prov}
bajas <- table(data_df$PROVBAJA)
altas <- table(data_df$PROVALTA)

#Comprobamos si el número de altas es el mismo número que de bajas para poder realizar la comparación correctamente
sum(bajas)==sum(altas)

var_provincias <- altas - bajas
```

El dato más significativo que se observa es que España es un país con un mayor número de inmigrantes que de emigrantes y por consecuencia, la población en las diferentes provincias españolas aumenta. Además, otro dato curioso es que no se observa un decrecimiento en las provincias del interior de España "La España despoblada". 

Si analizamos todas las provincias o municipios, tenemos muchos niveles dentro del factor, así que vamos a intentar obtener información más relevante a través del estudio de las comunidades autónomas.

```{r univ-comus}
bajas <- table(data_df$COMUBAJA)
altas <- table(data_df$COMUALTA)

#Comprobamos si el número de altas es el mismo número que de bajas para poder realizar la comparación correctamente
sum(bajas)==sum(altas)

var_com <- altas - bajas

#Eliminamos Extranjero para únicamente estudiar el terriorio nacional

elim <- c('Extranjero')
var_com <- var_com[!(names(var_com) %in% elim)]


plot_file <- "./figure/barplot_diffs.jpg"
if (!useJPGs | !file.exists(plot_file)) {
  jpeg(plot_file, width = 500, height = 350)
  barplot(var_com, names.arg = names(var_com),
          cex.names = 0.5, las=2, main = "Diferencia entre Altas y Bajas",
          xlab = "Categorías", ylab = "Diferencia")
  dev.off()
}
img <- load.image(plot_file)
par(mar = c(0, 0, 0, 0))
plot(img, axes = FALSE)
```

## Análisis bivariante

### Numérica - Numérica

La variable ANONAC debería tener una gran correlación con la variable EDAD.

```{r bivar-anonac-edad1}
bivar <- data_df %>%
  dplyr::select(ANONAC, EDAD) %>%
  na.omit()

plot_file <- "./figure/pairs_anonac_edad.jpg"
if (!useJPGs | !file.exists(plot_file)) {
  jpeg(plot_file, width = 500, height = 350)
  pairs(bivar)
  dev.off()
}
img <- load.image(plot_file)
par(mar = c(0, 0, 0, 0))
plot(img, axes = FALSE)
```

Efectivamente, como era de suponer, obtenemos que las dos variables están correlacionadas totalmente, ya que EDAD= 2021 - ANONAC.

```{r bivar-anonac-edad2}
cov <- cov(bivar, use='complete.obs')

print(cov)

cor_pearson <- cor(bivar, method = "pearson", use = "complete.obs")

print(cor_pearson)

cor_spearman <- cor(bivar, method= 'spearman', use='complete.obs')

print(cor_spearman)
```

La correlación de Pearson sirve para cuando la relación entre dos variables es lineal, mientras que la de Spearman es robusta frente a relaciones no lineales en datos ordenados. Por esta razón, ambas correlaciones son iguales, ya que la relación entre ambas variables es lineal.

### Numéricas- Categóricas

Seguidamente, utilizando la librería `ggplot` vamos a representar un histograma de edades por sexo, ya que queremos conocer la edad a la cual la gente suele cambiar de residencia y si existe alguna diferencia significativa entre hombres y mujeres a la hora de tomar esta decisión.

```{r hist-num-cat}
plot_file <- "./figure/hist_edad_sexo.jpg"
if (!useJPGs | !file.exists(plot_file)) {
  ggplot(data_df, aes(x=EDAD, fill=SEXO)) +
    geom_histogram(binwidth=5, position="dodge") +
    labs(
      title="Histograma de Edades por Sexo",
      x="Edad",
      y="Frecuencia"
    ) +
    scale_fill_manual(values=c("Hombre"="blue", "Mujer"="pink"))
  ggsave(plot_file, width = 1500, height = 1000, units = "px")
}
img <- load.image(plot_file)
par(mar = c(0, 0, 0, 0))
plot(img, axes = FALSE)
```

En esta gráfica, se observa que la gente cambia más de residencia alrededor de los 30 años, lo cual tiene sentido, ya que es la etapa de la vida en la que muchas personas deciden independizarse o formar una nueva familia.

Si queremos estudiar ambas colas, un detalle importante a tener en cuenta y que está apoyado científicamente es que las mujeres viven más de media que los hombres y lo podemos observar a edades tardías, ya que hay una diferencia significativa entre hombres y mujeres a esa edad. Por otra parte, también se observa que tras el nacimiento de los hijos o en muchas ocasiones del segundo hijo de la pareja, las familias suelen tomar la decisión de mudarse a un hogar más amplio.

Seguidamente, mediante un test T veremos si podemos considerar que las medias para hombres y mujeres son iguales.

```{r boxplot-sexo}
mujeres <- filter(data_df, SEXO == "Mujer")
hombres <- filter(data_df, SEXO=='Hombre')

t.test(mujeres$EDAD,hombres$EDAD)

plot_file <- "./figure/boxplot_edad_sexo.jpg"
if (!useJPGs | !file.exists(plot_file)) {
  ggplot(data_df, aes(x = SEXO, y = EDAD, fill = SEXO)) +
    geom_boxplot() +
    labs(title = "Boxplot of EDAD by SEXO", x = "SEXO", y = "EDAD")
  ggsave(plot_file, width = 1500, height = 1000, units = "px")
}
img <- load.image(plot_file)
par(mar = c(0, 0, 0, 0))
plot(img, axes = FALSE)
```

Por tanto, rechazamos la hipótesis nula de que las medias de edad de los hombres y las mujeres es la misma.

### Categóricas - Categóricas

Para seguir con el estudio del éxodo rural, podemos representar la relación entre el tamaño de los municipios de alta y de baja en un mosaico. Por limpieza, hemos recodificado las categorías de tamaño de la siguiente manera:

| Código en el mosaico | Descripción |
| -:- | -:- |
| tam_1 | Municipio no capital hasta 10.000 habitantes |
| tam_2 | Municipio no capital de 10.001 a 20.000 |
| tam_3 | Municipio no capital de 20.001 a 50.000 |
| tam_4 | Municipio no capital de 50.001 a 100.000 |
| tam_5 | Municipio no capital  de más de 100.000 |
| capital | Municipio capital de provincia |

```{r mosaic-tamu}
mosaic_df <- data_df[
  complete.cases(data_df[c("SEXO", "TAMUALTA", "TAMUBAJA")]),]

levels(mosaic_df$TAMUBAJA) <- c(paste0("tam_", 1:5), "capital")
levels(mosaic_df$TAMUALTA) <- c(paste0("tam_", 1:5), "capital")

plot_file <- "./figure/mosaic_tamu.jpg"
if (!useJPGs | !file.exists(plot_file)) {
  ggplot(mosaic_df) +
    geom_mosaic(aes(
      x = product(TAMUALTA, TAMUBAJA),
      fill = TAMUALTA)) +
    geom_mosaic_text(
      aes(
        x = product(TAMUALTA, TAMUBAJA),
        label = after_stat(.wt)),
      as.label = TRUE) +
    labs(
      title = "Variaciones residenciales frente a tamaños",
      x = "TAMUBAJA",
      y = "TAMUALTA") +
    theme_minimal() +
    guides(fill = "none")
  ggsave(plot_file, width = 1500, height = 1000, units = "px")
}
img <- load.image(plot_file)
par(mar = c(0, 0, 0, 0))
plot(img, axes = FALSE)
```

Para complementar este análisis, transformamos nuestros datos a fin de obtener un `data.frame` con la siguiente estructura:

 - **MUNI**: contiene todos los valores únicos de las variables **MUNIALTA** y **MUNIBAJA**.

 - **TAMU**: valor correspondiente de **TAMUALTA** / **TAMUBAJA**.
 
 - **isCAPITAL**: valor lógico que indica si el municipio es capital.
 
 - **EDAD**: media de la edad de los desplazados desde ó hasta cada municipio.
 
 - **MES**: moda del mes en el que se producen los movimientos desde ó hasta cada municipio.
 
 - **nBAJAS**: número de bajas en cada municipio.
 
 - **nALTAS**: número de bajas en cada municipio.
 
Las variables adicionales **nTOTAL** y **nNETO** son la suma y la diferencia de las últimas dos variables listadas.

```{r rearrange-muni}
muni_df <- rearrange_muni_data(data_df)
```

Ahora podemos realizar diferentes representaciones sobre este nuevo dataset transformado.

```{r muni-plots}
muni_df <- muni_df %>%
  dplyr::select(MUNI, TAMU, nNETO, isCAPITAL)

plot_file <- "./figure/boxplot_tamu.jpg"
if (!useJPGs | !file.exists(plot_file)) {
  muni_df %>%
    na.omit()%>%
    filter(TAMU != "Municipio capital de provincia") %>%
    ggplot(aes(y = nNETO, color = TAMU)) +
      geom_boxplot() +
      labs(
        y = "desplazamientos netos",
        title = "Variación neta en función del tamaño")
  ggsave(plot_file, width = 1500, height = 1000, units = "px")
}
img <- load.image(plot_file)
par(mar = c(0, 0, 0, 0))
plot(img, axes = FALSE)

plot_file <- "./figure/boxplot_capital.jpg"
if (!useJPGs | !file.exists(plot_file)) {
    muni_df %>%
    na.omit()%>%
    ggplot(aes(x = isCAPITAL, y = nNETO, fill = isCAPITAL)) +
    geom_violin() +
    labs(
      y = "desplazamientos netos",
      title = "Variación neta en función de isCAPITAL")
  ggsave(plot_file, width = 1500, height = 1000, units = "px")
}
img <- load.image(plot_file)
par(mar = c(0, 0, 0, 0))
plot(img, axes = FALSE)
```

Como cabía esperar, el número las variaciones residenciales netas de los municipios más grandes es más elevado, esto es, sí observamos un cierto grado de centralización por el cual un gran número de personas se desplaza hacia las ciudades más grandes.

## Análisis interactivo: mapas

Empleamos la librería `leaflet` para crear mapas interactivos sobre los que representamos algunos de los resultados obtenidos en el análisis. En este documento se expone una imagen fija de uno de ellos. Para poder consultar los mapas en su totalidad, ejecute el documento `ProyectoAED2023.Rmd`.

```{r plot-countries, eval = F}
country_data <- get_net_country_movements(data_df)
dict_countries <- get_country_location(fileDir = "./data/country_locations.RData")
countries_map <- plot_countries_map(country_data, dict_countries)
countries_map
```

```{r plot-prov, eval = F}
selected_prov <- "Palencia"
prov_data <- get_net_prov_movements(data_df, selected_prov)
dict_prov <- get_prov_location(fileDir = "./data/prov_locations.RData")
residence_variations_map <- plot_residence_variation_map(prov_data, dict_prov, selected_prov)
residence_variations_map
```

### Características

Se usa el test Chi-cuadrado. Este test supone una hipótesis de
partida Ho (Son independientes) y dependiendo del resultado del
test, se acepta o no:

p<0.05: Rechazamos hipótesis
p \(\geq\) 0.05: Aceptamos Ho

```{r chisq-comu}
tablacontingencia1 <- table(data_df$COMUBAJA, data_df$COMUALTA)
chitest1 <- chisq.test(tablacontingencia1, correct = FALSE)
print(chitest1)
```

Por tanto, como p \(\geq\) < 0.05, rechazamos la hipótesis nula. y por tanto, concluimos que las variables COMUBAJA y COMUALTA son dependendientes.

## Análisis de outliers y datos faltantes

Respecto a los valores NA, hemos decidido no imputar ningún valor faltante, ya que consideramos que nuestra muestra es suficientemente grande como para poder trabajar sin dichos valores y es preferible no introducir datos que modifiquen las características de nuestro conjunto de datos.

Respecto a los outliers, únicamente hemos encontrado en la variable EDAD aunque no se pueden considerar valores imposibles, puesto que una persona puede vivir 110 años.

```{r outliers}

## Análisis outliers Boxplot
outliers <- data_df %>%
  dplyr::select(EDAD) %>%
  summarise(Media=mean(EDAD), Mediana=median(EDAD), IQR=IQR(EDAD), Q1 = quantile(EDAD,0.25),Q3 = quantile(EDAD, 0.75),
ValorMinBoxplot= quantile(EDAD,0.25)-1.5*IQR(EDAD),           
ValorMaxBoxplot=quantile(EDAD,0.75)+1.5*IQR(EDAD) )
outliers

resumen <- outliers %>%
  unite(intervalo, ValorMinBoxplot, ValorMaxBoxplot, sep = " - ")
resumen

valorescriticos<- data_df %>%
  filter(EDAD > 81.5) %>%
  count()
valorescriticos

outliers <- data_df %>%
  group_by(SEXO) %>%
  dplyr::select(EDAD) %>%
  summarise(Media=mean(EDAD), Mediana=median(EDAD), IQR=IQR(EDAD), Q1 = quantile(EDAD,0.25),Q3 = quantile(EDAD, 0.75),
ValorMinBoxplot= quantile(EDAD,0.25)-1.5*IQR(EDAD),           
ValorMaxBoxplot=quantile(EDAD,0.75)+1.5*IQR(EDAD) )
outliers

resumen <- outliers %>%
  unite(intervalo, ValorMinBoxplot, ValorMaxBoxplot, sep = " - ")
resumen

valorescriticos<- data_df %>%
  group_by(SEXO) %>%
  filter(SEXO=='Mujer',EDAD > 85.5) %>%
  count()
valorescriticos

valorescriticos<- data_df %>%
  group_by(SEXO) %>%
  filter(SEXO=='Hombre',EDAD > 81.5) %>%
  count()
valorescriticos
```

```{r}
# Análisis outliers Regla 3 Sigma

library(dplyr)
outliers_sigma <- data_df %>%
  dplyr::select(EDAD) %>%
  summarise(Sigma=mean(EDAD) + 3*sd(EDAD))
outliers_sigma

valorescriticos_sigma<- data_df %>%
  filter(EDAD > 93.5) %>%
  count()
valorescriticos_sigma


outliers <- data_df %>%
  group_by(SEXO) %>%
  dplyr::select(EDAD) %>%
  summarise(Sigma=mean(EDAD) + 3*sd(EDAD) )
outliers

valorescriticos_sigmah<- data_df %>%
  group_by(SEXO) %>%
  filter(SEXO=='Hombre',EDAD > 91.3) %>%
  count()
valorescriticos_sigmah

valorescriticos_sigmam<- data_df %>%
  group_by(SEXO) %>%
  filter(SEXO=='Mujer',EDAD > 95.8) %>%
  count()
valorescriticos_sigmam
```

```{r}
# Identificador Hampel
3*mad(data_df$EDAD)
```
La regla del identificador de Hampel es el único que no considera que la distribución sea gaussiana. Sin embargo, etiqueta como outliers valores que realmente no lo son. Por otra parte, pese a que la Edad no sigue una distribución gaussiana, la regla 3 sigma es muy poco agresiva para la detección de outliers y por tanto, es la que menos valores detecta como outliers.

# Conclusiones finales